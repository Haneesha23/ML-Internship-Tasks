{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d75faf1-cc19-45a3-9df0-18c8a2486c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ FINAL SENTIMENT ANALYSIS RESULT:\n",
      "\n",
      "                                      text                 cleaned_text  \\\n",
      "0          I love working in this company!         love working company   \n",
      "1  The workload is too much and stressful.      workload much stressful   \n",
      "2      My team is supportive and friendly.     team supportive friendly   \n",
      "3            I am unhappy with the salary.               unhappy salary   \n",
      "4             The new project is exciting!         new project exciting   \n",
      "5      The office environment is horrible.  office environment horrible   \n",
      "6    I feel neutral about today's meeting.  feel neutral todays meeting   \n",
      "\n",
      "                                           sentiment    neg    neu    pos  \\\n",
      "0  {'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'comp...  0.000  0.323  0.677   \n",
      "1  {'neg': 0.623, 'neu': 0.377, 'pos': 0.0, 'comp...  0.623  0.377  0.000   \n",
      "2  {'neg': 0.0, 'neu': 0.156, 'pos': 0.844, 'comp...  0.000  0.156  0.844   \n",
      "3  {'neg': 0.737, 'neu': 0.263, 'pos': 0.0, 'comp...  0.737  0.263  0.000   \n",
      "4  {'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'comp...  0.000  0.385  0.615   \n",
      "5  {'neg': 0.636, 'neu': 0.364, 'pos': 0.0, 'comp...  0.636  0.364  0.000   \n",
      "6  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.000  1.000  0.000   \n",
      "\n",
      "   compound  \n",
      "0    0.6369  \n",
      "1   -0.5106  \n",
      "2    0.6597  \n",
      "3   -0.4215  \n",
      "4    0.4939  \n",
      "5   -0.5423  \n",
      "6    0.0000  \n",
      "\n",
      "âœ” Output saved as: task3_sentiment_analysis_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "data = {\n",
    "    \"text\": [\n",
    "        \"I love working in this company!\",\n",
    "        \"The workload is too much and stressful.\",\n",
    "        \"My team is supportive and friendly.\",\n",
    "        \"I am unhappy with the salary.\",\n",
    "        \"The new project is exciting!\",\n",
    "        \"The office environment is horrible.\",\n",
    "        \"I feel neutral about today's meeting.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(sentence):\n",
    "    # Lowercase\n",
    "    sentence = sentence.lower()\n",
    "    # Remove punctuation\n",
    "    sentence = sentence.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Tokenize\n",
    "    words = sentence.split()\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join back\n",
    "    cleaned = \" \".join(words)\n",
    "    return cleaned\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(sentence):\n",
    "    return sia.polarity_scores(sentence)\n",
    "\n",
    "df[\"sentiment\"] = df[\"cleaned_text\"].apply(get_sentiment)\n",
    "\n",
    "\n",
    "df_sentiment = df[\"sentiment\"].apply(pd.Series)\n",
    "df = pd.concat([df, df_sentiment], axis=1)\n",
    "\n",
    "\n",
    "print(\"ðŸ“Œ FINAL SENTIMENT ANALYSIS RESULT:\\n\")\n",
    "print(df)\n",
    "\n",
    "df.to_csv(\"task3_sentiment_analysis_output.csv\", index=False)\n",
    "print(\"\\nâœ” Output saved as: task3_sentiment_analysis_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f32570-c1dd-4a04-9326-35294da8482d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1aef7f-8015-48e4-ab06-2b3b861ce41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6c2b4-36c5-4030-9eb5-8c559a186049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da08d13-b6b2-4164-8a69-60bc1ebe7aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c68ef-6ec8-4be3-93fc-6c8ec873c2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
